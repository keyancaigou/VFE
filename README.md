# VEF: Video Event Future Dataset

This repository contains the VEF dataset, designed to facilitate research in video understanding and future event prediction.

## Overview

The VEF dataset comprises a collection of video clips, each accompanied by descriptions of premise events and predicted descriptions of subsequent events. It is intended for use in tasks such as video captioning and future event prediction.

## Dataset Structure

The dataset is organized into the `data/`, please see `data/readme.md` for details.

## Baseline

The baseline model is released at `baseline/`, please see `baseline/readme.md` for details.

## Usage

To use the VEF dataset, follow these steps:

1. Clone the repository or download the dataset files.
2. Extract the dataset files if necessary.
3. Use the provided annotations to train and evaluate your models.

## Related Work
* [Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA)
* [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
* [VideoChat](https://github.com/OpenGVLab/Ask-Anything)
* [MovieChat](https://github.com/rese1f/MovieChat)

## Citation

If you use the VEF dataset in your research, please cite it as follows:
